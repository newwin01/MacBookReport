## 머신 러닝 및 딥러닝 알고리즘에 대한 공부

- 머신 러닝 및 딥러닝 알고리즘에 대한 공부
- 2023.8.28 ~ 2023.12.15
- 머신 러닝(Machine Learning)은 컴퓨터가 데이터를 기반으로 패턴을 학습하고 의사 결정을 내리는 인공 지능의 한 분야입니다. 이는 명시적인 프로그래밍 없이도 컴퓨터가 데이터에서 학습하고 새로운 데이터를 예측하거나 분석할 수 있게 하는 기술을 포함합니다.
머신 러닝에는 여러 이론을 바탕으로 한 알고리즘이 존재합니다. 머신 러닝은 크게 3가지로 나눌 수 있습니다. 지도 학습은 입력 데이터와 해당 데이터에 대한 라벨(정답)이 함께 제공되는 상황에서 모델을 학습하는 방법입니다. 모델은 입력과 라벨 간의 관계를 학습하고, 이후 새로운 입력에 대한 라벨을 예측할 수 있습니다. 예를 들어, 이메일이 스팸인지 아닌지를 판별하는 모델을 학습하는 경우가 있습니다. 비지도 학습은 라벨이 없는 데이터를 사용하여 모델을 학습하는 방법입니다. 주어진 데이터에서 패턴이나 구조를 발견하고, 데이터를 그룹화하거나 차원을 축소하여 특징을 추출합니다. 군집화(Clustering)나 차원 축소(Dimensionality Reduction)가 비지도 학습의 예시입니다. 강화 학습은 에이전트가 환경과 상호 작용하며 특정 작업을 수행하도록 학습하는 방법입니다. 에이전트는 행동을 취하고, 그에 대한 보상을 받아서 정책(policy)을 최적화하려고 합니다. 게임이나 로봇 제어 등에 사용됩니다.
이를 바탕으로 다양한 알고리즘을 구현할 수 있습니다. 일반적인 알고리즘에는 선형 회귀(Linear Regression), 의사결정 트리(Decision Trees), 신경망(Neural Networks), K-최근접 이웃(K-Nearest Neighbors), K-평균 군집화(K-Means Clustering) 등이 포함됩니다.

- 다음의 Code들은 여러 알고리즘을 구현했습니다. 

### Density Estimation 

Density Estimation(밀도 추정)은 주어진 데이터의 분포를 모델링하고, 이를 통해 확률밀도함수(probability density function, PDF)를 추정하는 과정입니다. 데이터셋이 어떻게 값들이 분포하는지를 알면, 이를 기반으로 새로운 데이터의 확률을 예측할 수 있습니다.

커널 밀도 추정을 중점적으로 구현했습니다. 데이터 포인트 주변에 커널(일종의 함수)을 배치하고, 이를 통해 전체 데이터셋의 밀도를 추정합니다. 대표적으로 가우시안 커널을 사용하는 가우시안 커널 밀도 추정(Gaussian Kernel Density Estimation)이 있습니다.

[code](./density%20estimation.ipynb)

### kMeans

k-Means는 클러스터링 알고리즘 중 하나로, 주어진 데이터를 k개의 클러스터로 그룹화하는 비지도 학습 방법입니다. 알고리즘은 데이터 포인트들을 중심과의 거리에 기반하여 가장 가까운 클러스터로 할당하고, 각 클러스터의 중심을 다시 계산하여 업데이트합니다. 이러한 과정을 반복하여 클러스터의 중심이 수렴하면 알고리즘이 종료됩니다.

[code](./kMeans.ipynb)

### kNN and Random Forest

k-NN (k-Nearest Neighbors)은 지도 학습 알고리즘으로, 새로운 데이터 포인트를 주변 k개의 이웃들과 비교하여 분류 또는 회귀를 수행하는 알고리즘입니다. 데이터 포인트와 이웃들 간의 거리를 계산하고, 가장 많은 이웃들이 속한 클래스나 평균값을 예측값으로 사용합니다.

Random Forest는 앙상블 학습 기법 중 하나로, 여러 결정 트리를 조합하여 더 강력하고 안정적인 모델을 형성합니다. 각 트리는 부트스트랩 샘플링을 통해 랜덤하게 선택된 데이터로 학습하고, 각 노드에서 최적의 특성을 선택하여 트리를 성장시킵니다. 최종 예측은 각 트리의 결과를 평균 또는 다수결 투표를 통해 결합하여 수행됩니다.

[code](./kNN%20and%20Random%20Forest.ipynb)

### MLP

다층 퍼셉트론(MLP)은 인공 신경망의 한 종류로, 여러 개의 은닉층을 가진 다층 구조로 이루어져 있습니다. 각 은닉층의 뉴런은 활성화 함수를 통과하며 입력을 변환하고, 다양한 가중치를 학습하여 복잡한 비선형 관계를 모델링할 수 있습니다. 역전파 알고리즘을 사용하여 손실을 최소화하며 가중치를 조절하고, 다양한 분야에서 분류, 회귀 등 다양한 문제에 적용됩니다.

[code](./MLP.ipynb)

### PCA and LDA

주성분 분석(PCA)은 고차원 데이터의 차원을 줄이고 주요한 정보를 보존하는 선형 변환 기술로, 데이터의 분산을 최대화하는 새로운 축을 찾아 차원을 축소합니다. 선형 판별 분석(LDA)은 클래스 간 분산을 최대화하고 클래스 내 분산을 최소화하여 데이터를 특성 공간으로 투영하여 분류 목적으로 사용됩니다. PCA는 차원 축소와 데이터 압축에 주로 사용되며, LDA는 판별력 있는 특성을 추출하여 분류 문제에 효과적으로 활용됩니다.

[code](./PCA%20and%20LDA.ipynb)

### RBFN

Radial Basis Function Network(RBFN)은 입력층, 은닉층, 출력층으로 구성된 인공 신경망으로, 은닉층의 노드에 Radial Basis Function을 사용하여 입력 데이터를 비선형적으로 매핑합니다. RBFN은 주로 분류 및 회귀 작업에 활용되며, 입력 데이터를 은닉층에서 Radial Basis Function을 사용하여 특성 공간으로 투영하고, 이를 통해 출력층에서 원하는 결과를 얻습니다. 네트워크의 중심 및 폭 매개변수는 학습을 통해 조정되어 입력 데이터를 잘 표현하도록 최적화됩니다.

[code](./RBFN.ipynb)

### tSNE

t-Distributed Stochastic Neighbor Embedding (t-SNE)는 고차원 데이터를 저차원으로 효과적으로 시각화하기 위한 비선형 차원 축소 기술입니다. 데이터 포인트 간의 유사성을 보존하며 차원을 축소하여 시각적으로 인접한 관계를 유지합니다. 특히 군집 감지와 시각적 데이터 분석에 유용하며, 데이터의 복잡한 구조를 탐색하는 데 활용됩니다.

[code](./tSNE.ipynb)